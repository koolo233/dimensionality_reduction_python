{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性判别分析(Fisher's Linear Discriminant, FLD)\n",
    "\n",
    "## 符号定义\n",
    "\n",
    "|符号|定义|\n",
    "|:-:|:-:|\n",
    "|$\\bm{x}$|样本点|\n",
    "|$N$|数据总数|\n",
    "|$X$|样本集合|\n",
    "|$l$|总类别数|\n",
    "|$\\bm{m}$|均值向量|\n",
    "|$y$|每一个样本点对应的类别|\n",
    "|$\\bm{w}$|投影向量|\n",
    "|$C$|协方差矩阵|\n",
    "|$S$|散度矩阵|\n",
    "|$k$|降维后维度|\n",
    "|$\\sigma$|每一个类降维后的标准差|\n",
    "|$\\mu$|每一个类降维后的均值向量|\n",
    "\n",
    "## PCA的缺陷\n",
    "\n",
    "PCA得到的降维总是向着最大化方差的方向进行投影，这一策略往往是有效的。直观上来说，向着最大化方差的方向投影显然能最大程度上离散原始的数据点，即使得降维后的数据尽量可分。\n",
    "\n",
    "但是在一些极端情况下，这一策略可能会失效。对于细粒度数据，其类间差距小，而类内差距大，若依然向着最大化方差的方向进行降维，显然同类别的数据由于类内差距大而分离，不同类别的数据由于类间差距小而降维到相似的坐标。对于细粒度的数据，显然，同类别的数据降维后聚合到一起，不同类别的数据相互分离才是有效的降维结果\n",
    "\n",
    "FLD正是这样一种能依靠已有数据进行监督降维的方法。类似于PCA，FLD也是一种线性的降维方法，因此其可以视为原数据点向某些方向进行投影\n",
    "\n",
    "## 应用于二维二分类的FLD\n",
    "\n",
    "对于分类问题，往往希望降维后同类数据聚合到一起，而不同类的数据分离。\n",
    "\n",
    "这一描述显然涉及到两个关键问题\n",
    "* 同类数据聚合到一起：每一类的方差尽可能小\n",
    "* 不同类数据的距离尽可能大：类间平均距离大\n",
    "\n",
    "那么FLD的目标就是：最小化类内方差，最大化类间间距（每一个类的期望的距离）\n",
    "\n",
    "首先进行定义\n",
    "\n",
    "* 正样本集合\n",
    "$$\n",
    "\\begin{equation}\n",
    "    X_1 = \\{ \\bm{x_i}|1\\leq i \\leq N,\\ y_i=1\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 负样本集合\n",
    "$$\n",
    "\\begin{equation}\n",
    "    X_2 = \\{ \\bm{x_i}|1\\leq i \\leq N,\\ y_i=2\\}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 对应的均值向量\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\bm{m_1} = \\frac{1}{N_1}\\sum_{\\bm{x}\\in X_1}\\bm{x}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\bm{m_2} = \\frac{1}{N_2}\\sum_{\\bm{x}\\in X_2}\\bm{x}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 对应的协方差矩阵\n",
    "$$\n",
    "\\begin{equation}\n",
    "    C_1 = \\frac{1}{N_1}\\sum_{\\bm{x} \\in X_1}(\\bm{x}-\\bm{m_1})(\\bm{x}-\\bm{m_1})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    C_2 = \\frac{1}{N_2}\\sum_{\\bm{x} \\in X_2}(\\bm{x}-\\bm{m_2})(\\bm{x}-\\bm{m_2})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 对应的散度矩阵\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_1 = \\sum_{\\bm{x} \\in X_1}(\\bm{x}-\\bm{m_1})(\\bm{x}-\\bm{m_1})^T = N_1C_1\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_2 = \\sum_{\\bm{x} \\in X_2}(\\bm{x}-\\bm{m_2})(\\bm{x}-\\bm{m_2})^T= N_2C_2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 对应的均值降维结果\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mu_1 = \\bm{m_1}^T\\bm{w}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mu_2 = \\bm{m_2}^T\\bm{w}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* 对应的降维后标准差\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\sigma_1 \n",
    "    &= \\sqrt{\\frac{1}{N_1}\\sum_{\\bm{x}\\in X_1}(\\bm{x}^T\\bm{w}-\\bm{m_1}^T\\bm{w})^2} \\\\\n",
    "    &= \\sqrt{\\bm{w}^T C_1 \\bm{w}} \\\\\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\sigma_2 \n",
    "    &= \\sqrt{\\frac{1}{N_2}\\sum_{\\bm{x}\\in X_2}(\\bm{x}^T\\bm{w}-\\bm{m_2}^T\\bm{w})^2} \\\\\n",
    "    &= \\sqrt{\\bm{w}^T C_2 \\bm{w}} \\\\\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "因此FLD的目标：最小化类内方差，最大化类间间距（每一个类的期望的距离）可以被翻译为如下的几种形式：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\frac{|\\mu_1-\\mu_2|}{\\sigma_1 + \\sigma_2}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\frac{|\\mu_1-\\mu_2|}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "以及\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\frac{(\\mu_1-\\mu_2)^2}{\\sigma1_1^2 + \\sigma_2^2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "式-13相较于上述的式-11和式-12，其显然要便于后续的推导（既没有绝对值，也没有开方）\n",
    "\n",
    "将式-5、式-6、式-7、式-8、式-9和式-10带入式-13可得\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "    \\mathcal{L} \n",
    "    &= \\frac{(\\mu_1-\\mu_2)^2}{\\sigma1_1^2 + \\sigma_2^2} \\\\\n",
    "    &= \\frac{\\bm{w}^T(\\bm{m_1}-\\bm{m_2})(\\bm{m_1}-\\bm{m_2})^T\\bm{w}}{\\bm{w}^T(C_1+C_2)\\bm{w}}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "若将上式中的协方差矩阵换为散度矩阵可以得到最为原始的FLD形式\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathcal{L} = \\frac{\\bm{w}^T(\\bm{m_1}-\\bm{m_2})(\\bm{m_1}-\\bm{m_2})^T\\bm{w}}{\\bm{w}^T(S_1+S_2)\\bm{w}}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "显然，替换为散度矩阵后并不影响上述损失的最优解\n",
    "\n",
    "进一步将式-17简写为如下的形式\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathcal{L} = \\frac{\\bm{w}^TS_B\\bm{w}}{\\bm{w}^TS_W\\bm{w}}\n",
    "\\end{equation}\n",
    "$$\n",
    "其中$S_B$为类间散度矩阵，$S_W$为类内散度矩阵\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_B = (\\bm{m_1}-\\bm{m_2})(\\bm{m_1}-\\bm{m_2})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_W = S_1+S_2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "有了上述定义后，显然优化目标是$\\max\\mathcal{L}$\n",
    "对$\\bm{w}$求偏导可得\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial{\\mathcal{L}}}{\\partial{\\bm{w}}} = \\frac{2((\\bm{w}^TS_W\\bm{w})S_B\\bm{w}-(\\bm{w}^TS_B\\bm{w})S_W\\bm{w})}{(\\bm{w}^TS_W\\bm{w})^2} = 0\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "可得：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_B\\bm{w} = \\frac{\\bm{w}^TS_B\\bm{w}}{\\bm{w}^TS_W\\bm{w}}S_W\\bm{w}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "显然$\\bm{w}$为上式的一个广义特征向量，而$\\mathcal{L} = \\frac{\\bm{w}^TS_B\\bm{w}}{\\bm{w}^TS_W\\bm{w}}$是上式的一个广义特征值，考虑到优化目标是$\\max{\\mathcal{L}}$，因此$\\bm{w}$的最优解为式-22最大广义特征值对应的特征向量\n",
    "\n",
    "## 应用于二分类的FLD\n",
    "上述分析同样适用于多于二维的数据点，类似于PCA中的分析，仅需要提取式-22前k个最大广义特征值对应的特征向量就可以得到k维子空间下的降维结果\n",
    "\n",
    "## 应用于多分类的FLD\n",
    "对于多分类，其基本原则没有改变：依然是尽可能增大降维后的类间距离并减小类内方差，但是不同的是类间散度以及类内散度的计算方法。\n",
    "\n",
    "对于类内散度，其定义扩展为子集的散度矩阵之和\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_W = \\sum_{i=1}^lS_i = \\sum_{i=1}^l \\sum_{\\bm{x} \\in X_i}(\\bm{x}-\\bm{m_i})(\\bm{x}-\\bm{m_i})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "对于类间散度，若依然依照二分类的定义，则会计算$l\\times l$个矩阵并求和，这样显然效率低下\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_B = \\sum_{i=1}^l\\sum_{j=1}^l(\\bm{m_i}-\\bm{m_j})(\\bm{m_i}-\\bm{m_j})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "实际使用的为\n",
    "$$\n",
    "\\begin{equation}\n",
    "    S_B = \\sum_{i=1}^lN_i(\\bm{m_i}-\\bm{m})(\\bm{m_i}-\\bm{m})^T\n",
    "\\end{equation}\n",
    "$$\n",
    "其中$\\bm{m}$为所有数据的均值。上式考虑到了不同类的数据数量的差异，对于不同类的数据量存在显著差异的情况，这一处理显然是有利的。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
