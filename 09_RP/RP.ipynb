{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机映射（Random Projection, RP）\n",
    "\n",
    "## 符号定义\n",
    "\n",
    "|符号|含义|\n",
    "|:--:|:--:|\n",
    "|$\\pmb{x}$|数据点|\n",
    "|$\\pmb{y}$|降维后数据点|\n",
    "|$S$|数据点集合|\n",
    "|$N$|数据点总数|\n",
    "|$f$|映射函数|\n",
    "|$d$|降维前维度|\n",
    "|$m$|降维后维度|\n",
    "|$\\epsilon$|常数|\n",
    "|$Z$|映射矩阵|\n",
    "\n",
    "## 概念\n",
    "\n",
    "随机映射尝试了一个非常大胆的降维思路：通过一个随机生成的映射函数直接将高维空间中的数据点嵌入到低维空间，并且保证数据点之间的欧式距离变化存在一个上界和下界（失真可控）。\n",
    "\n",
    "降维方法往往需要基于一定的假设或者说降维的目标，例如PCA的一种解释是PCA以最大方差的方向对原始数据进行降维，LLE则假设降维前后每一个数据点均可以由其周围的点以相同的权重线性表示。随机映射则保证数据点之间的降维前后欧式距离的变化存在一个上界和下界。\n",
    "\n",
    "随机映射最为吸引人的地方无疑是其映射函数的随机性。无需计算距离或是特征向量的特点显然能大大加快降维的速度。\n",
    "\n",
    "随机映射的理论保证是Johnson–Lindenstrauss lemma，Johnson–Lindenstrauss lemma的内容如下：\n",
    "\n",
    "假设存在一个数据集，$S=\\{\\pmb{x_i}\\}_{i=1}^N, \\pmb{x_i}\\in\\mathcal{R}^d$，d是一个相当高的维数。给定一个常数$\\epsilon, 0\\leq\\epsilon\\leq 1$，则存在一个映射函数$f:\\mathcal{R}^d\\rightarrow\\mathcal{R}^m, m\\geq\\frac{4\\ln(N)}{\\frac{\\epsilon^2}{2} - \\frac{\\epsilon^3}{3}}$，有如下结论：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    (1-\\epsilon)||\\pmb{x_i}-\\pmb{x_j}||^2\\leq||f(\\pmb{x_i})-f(\\pmb{x_j})||^2\\leq(1+\\epsilon)||\\pmb{x_i}-\\pmb{x_j}||^2, \\forall \\pmb{x_i}, \\pmb{x_j}\\in S\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Johnson–Lindenstrauss lemma表明对于一个高维空间的降维问题，总能找到一个映射函数使得降维后任何两个数据点之间的距离是原空间中这两个数据点欧式距离的$[1-\\epsilon, 1+\\epsilon]$倍范围内。\n",
    "\n",
    "在Johnson–Lindenstrauss lemma的基础上，又能证明从高斯分布$\\mathcal{N}(0, \\frac{1}{\\sqrt m})$随机采样生成的映射矩阵大概率正好能满足上述条件。\n",
    "\n",
    "因此使用从高斯分布$\\mathcal{N}(0, \\frac{1}{\\sqrt m})$随机采样生成的映射矩阵对数据进行降维能够在Johnson–Lindenstrauss lemma的保证下实现较为可靠的降维。\n",
    "\n",
    "## 算法流程\n",
    "\n",
    "* 定义数据集、数据维度以及常数$\\epsilon$\n",
    "* 指定降维后维度$m$\n",
    "* 从高斯分布$\\mathcal{N}(0, \\frac{1}{\\sqrt m})$随机生成映射矩阵$Z$\n",
    "* 映射得到输出\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/158512304\n",
    "\n",
    "https://scikit-learn.org/stable/modules/random_projection.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound.html#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py\n",
    "\n",
    "https://web.njit.edu/~usman/courses/cs675_fall19/JL_lemma.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import random_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRP(object):\n",
    "\n",
    "    def __init__(self, eps=0.1, random_state=None):\n",
    "        self.eps = eps\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit_transform(self, input_data):\n",
    "\n",
    "        input_data = np.array(input_data)\n",
    "        n_samples, input_dims = input_data.shape\n",
    "\n",
    "        min_dims = self.judge_min_dim(n_samples, self.eps)\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        # create transfer matrix\n",
    "        transfer_mat = np.random.normal(loc=0, scale=1/np.sqrt(min_dims), size=(min_dims, input_dims))\n",
    "\n",
    "        output_mat = np.matmul(input_data, transfer_mat.T)\n",
    "        return output_mat\n",
    "\n",
    "    def judge_min_dim(self, n_samples, eps):\n",
    "        return int(4 * np.log(n_samples)/(pow(eps, 2)/2 - pow(eps, 3)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# --------------------- create data -----------------------\n",
    "sample_num = 100\n",
    "input_dims = 10000\n",
    "eps = 0.5\n",
    "\n",
    "input_data = np.random.rand(sample_num, input_dims)\n",
    "\n",
    "# -------------------- sklearn RP --------------------------\n",
    "sklearn_rp = random_projection.GaussianRandomProjection(eps=0.5, random_state=1024)\n",
    "sklearn_rp_result = sklearn_rp.fit_transform(input_data)\n",
    "\n",
    "# --------------------- My RP -----------------------------\n",
    "my_rp = MyRP(eps=0.5, random_state=1024)\n",
    "my_rp_result = my_rp.fit_transform(input_data)\n",
    "\n",
    "# compare result\n",
    "print(my_rp_result - sklearn_rp_result)\n",
    "print(np.linalg.norm(sklearn_rp_result-my_rp_result, ord='fro'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43439a6561311e12ff6e9f6b15eb417981da28cab937ea5918ec6285f5566bbf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('FlyAi_Pytorch1_5Python37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
